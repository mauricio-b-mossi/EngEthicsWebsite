<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Build an AI Shoe Designer (And Discover Its Flaw)</title>
    <link rel="stylesheet" href="style.css" />
  </head>

  <body>
    <h1>Lets Build a Shoe Designer With AI</h1>
    <p>
      In this tutorial, I‚Äôll show you how to build a completely free AI image
      generator that specializes in shoes. Whether you're a designer looking for
      inspiration, a sneakerhead dreaming up the next hype beast release, or
      just curious about AI, this guide will help you turn ideas into visuals
      with no cost beyond your computer‚Äôs hardware.
    </p>

    <div>
      <strong> No coding experience? No problem! </strong>
    </div>

    <ul>
      <li>We‚Äôll explain everything in plain language.</li>
      <li>
        You can copy-paste the code without understanding it (like following a
        recipe).
      </li>
      <li>
        Marvel at how just a few lines of code can produce stunning designs.
      </li>
    </ul>

    <!-- How AI Image Generation Works: -->
    <h2>How AI Image Generation Works</h2>

    <p>
      Before we build our shoe designer, let's understand the key components
      that make AI image generation possible. These concepts will help you grasp
      what's happening behind the scenes when your code generates images.
    </p>

    <h3>The Core Components</h3>

    <h4>1. The Model (The Artist's Brain)</h4>
    <ul>
      <li>
        <strong>What it is:</strong> A neural network trained on millions of
        images
      </li>
      <li>
        <strong>Our choice:</strong> Stable Diffusion - an open-source model
        that excels at detailed images
      </li>
      <li>
        <strong>Key capability:</strong> Understands relationships between text
        descriptions and visual features
      </li>
    </ul>

    <div class="analogy">
      Think of this as hiring a world-class artist who has memorized every shoe
      design ever published online, but can combine elements in completely new
      ways.
    </div>

    <h4>2. Diffusers (The Painting Toolkit)</h4>
    <ul>
      <li>
        <strong>What they do:</strong> Implement the "diffusion" process -
        gradually transforming random noise into coherent images
      </li>
      <li>
        <strong>Key advantage:</strong> Handles the complex math so we don't
        have to
      </li>
      <li>
        <strong>Our use:</strong> Provides the Stable Diffusion implementation
        we'll fine-tune
      </li>
    </ul>

    <h4>3. Datasets (The Reference Library)</h4>
    <ul>
      <li>
        <strong>Our collection:</strong> 200-500 Nike shoe images (enough to
        learn style without direct copying)
      </li>
      <li>
        <strong>Preparation:</strong> Images standardized to 512√ó512 pixels
      </li>
      <li>
        <strong>Critical detail:</strong> The AI learns patterns (swoosh shapes,
        textures) not exact copies
      </li>
    </ul>

    <img src="aigenm.png" style="max-width: 100%; width: auto" />

    <!-- Requirements -->
    <h2>Requirements</h2>
    <p>To follow along with the code, you'll need:</p>
    <ul>
      <li>
        A computer with an <strong>NVIDIA GPU (8GB+ VRAM recommended)</strong>
      </li>
      <li><strong>Python 3.8+</strong> installed</li>
      <li>Basic familiarity with the command line</li>
    </ul>

    <div class="warning">
      <strong>‚ö†Ô∏è Note:</strong> Without a GPU, training will be very slow.
      Consider using
      <a href="https://colab.research.google.com/" target="_blank"
        >Google Colab</a
      >
      for free GPU access.
    </div>

    <!-- Setup -->
    <h2>Step 1: Setup Your Environment</h2>
    <p>
      We'll install the AI "toolkit" ‚Äî a set of free libraries that enable your
      computer to generate images. Don‚Äôt worry about memorizing everything right
      now; you can always revisit this later. To ease any nerves, we‚Äôll walk you
      through exactly what‚Äôs being installed.
    </p>
    <div class="terminal">
      pip install torch torchvision --extra-index-url
      https://download.pytorch.org/whl/cu118
    </div>
    <p><strong>What this installs:</strong></p>
    <ul>
      <li>
        <strong>PyTorch (torch)</strong>: The engine that powers our AI. Think
        of it like the operating system for artificial intelligence.
      </li>
      <li>
        <strong>torchvision</strong>: Adds image processing capabilities to
        PyTorch (like teaching the engine to understand pictures).
      </li>
      <li>
        <strong>CUDA 11.8</strong> (via --extra-index-url): Lets your NVIDIA GPU
        accelerate the AI.
      </li>
    </ul>
    <div class="terminal">
      pip install diffusers transformers accelerate datasets
    </div>
    <p><strong>Our AI specialty tools:</strong></p>
    <ul>
      <li>
        <strong>diffusers</strong>: The actual image generator we'll use
        (contains Stable Diffusion - the same tech behind popular AI art tools).
      </li>
      <li>
        <strong>transformers</strong>: Helps the AI understand text prompts (so
        it knows what "futuristic sneaker" means).
      </li>
      <li>
        <strong>accelerate</strong>: Optimizes the AI to run efficiently on your
        hardware.
      </li>
      <li>
        <strong>datasets</strong>: Provides tools to organize our shoe images
        for training.
      </li>
    </ul>
    <div class="note">
      <strong>Why this matters:</strong> Together, these packages form a
      complete AI art studio - like giving Photoshop to a robot artist. The
      total installation will use about 4GB of space.
    </div>
    <p>
      <strong>For non-technical readers:</strong> This is like downloading an
      "AI Art App", but instead of using an app store, we're using Python's
      package system. The commands above handle everything automatically.
    </p>

    <!-- Data Collection -->
    <h2>Step 2: Prepare Shoe Dataset</h2>

    <div class="intro-box">
      <p>
        Every great AI model starts with quality data. For our shoe generator to
        the more the better, try to aim for about
        <strong>200-500 high-quality images</strong>.
      </p>
    </div>

    <h3>How to Gather Images</h3>

    <h4>Manual Collection <span class="recommended">Recommended</span></h4>
    <ul>
      <li>Visit shoe brand websites and authorized retailers</li>
      <li>Save product images one-by-one (high-resolution preferred)</li>
      <li>Organize in a folder named <code>shoe_dataset/</code></li>
    </ul>

    <h4>Alternative Sources</h4>
    <ul>
      <li>
        Public datasets (<a
          href="https://www.kaggle.com/datasets"
          target="_blank"
          >Kaggle</a
        >, Open Images)
      </li>
      <li>Stock photo sites with Creative Commons licenses</li>
      <li>Second-hand marketplaces (eBay product photos)</li>
    </ul>

    <div class="note">
      <p>
        <strong>Data Collection Reality Check:</strong> This is where AI meets
        real-world challenges. To train our shoe designer, we need hundreds of
        Nike images - but manually collecting them would take days. Here's the
        programmer's solution.
      </p>
    </div>

    <h3>A Word About Web Scraping</h3>
    <p>While automated scraping can save time, consider:</p>
    <ul>
      <li>Most websites prohibit scraping in their Terms of Service</li>
      <li>Brands actively employ anti-bot measures</li>
      <li>
        Legal alternatives exist (like the
        <a href="https://developer.nike.com/" target="_blank"
          >Nike Product API</a
        >)
      </li>
    </ul>
    <p>
      Learn web scraping concepts ethically using practice sites like
      <a href="http://books.toscrape.com/" target="_blank">books.toscrape.com</a
      >.
    </p>

    <h3>Ready-Made Option</h3>
    <p>For immediate testing, try legally-sourced datasets:</p>
    <p>
      üîó
      <a href="https://www.kaggle.com/datasets" target="_blank"
        >Search "sneakers" on Kaggle</a
      >
    </p>

    <!-- Training -->
    <h2>üéì Step 3: Train the AI Model</h2>
    <p>
      Now that you've collected hundreds of shoe images, it's time to
      <strong>teach your AI how to design</strong>. This process mimics how
      humans learn - by studying many examples, identifying patterns, and
      practicing recreating them.
    </p>

    <p>
      Create a file, for our example the file is named
      <code>train_shoe_ai.py</code>:
    </p>

    <div class="code-block">
      <pre><code>
    import torch
    from diffusers import StableDiffusionPipeline, UNet2DConditionModel
    from torch.optim import AdamW
    from pathlib import Path

    # 1. Load model with gradient tracking
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16
    ).to("cuda")

    # 2. Enable gradients for UNet
    pipe.unet.train()
    for param in pipe.unet.parameters():
        param.requires_grad = True  # Critical for training

    # 3. Setup optimizer
    optimizer = AdamW(pipe.unet.parameters(), lr=1e-4)

    # 4. Simplified training loop
    for epoch in range(3):  # Start small for testing
        for img_path in Path("./nike_shoes").glob("*.jpg"):
            try:
                # Load and preprocess image
                image = pipe.image_processor.preprocess(Image.open(img_path))
                
                # Convert to latent space
                latents = pipe.vae.encode(image.to(device="cuda", dtype=torch.float16)).latent_dist.sample() * 0.18215
                
                # Forward pass
                noise_pred = pipe.unet(latents, torch.zeros(1).long().to("cuda")).sample
                
                # Dummy loss (replace with real noise prediction in actual training)
                loss = torch.nn.functional.mse_loss(noise_pred, torch.randn_like(noise_pred))
                
                # Backward pass
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()
                
                print(f"Epoch {epoch}, Loss: {loss.item():.4f}")
                
            except Exception as e:
                print(f"Skipping {img_path} due to error: {str(e)}")

    # Save the trained model
    pipe.save_pretrained("./trained_shoe_model")
    </code></pre>
    </div>
    <p>
      <strong>Note on file paths:</strong> In this code, I'm using
      <code>"./shoes"</code> as my folder containing all the training images (in
      JPG format), and saving the final trained model to
      <code>"./trained_shoe_model"</code>. Make sure to:
    </p>
    <ul>
      <li>
        Create a <code>shoes</code> folder in the same directory as your script
      </li>
      <li>Place all your shoe images inside it</li>
      <li>
        The script will automatically create the
        <code>trained_shoe_model</code> folder
      </li>
    </ul>
    <p>Then run the file:</p>
    <div class="terminal">python train_shoe_ai.py</div>

    <!-- Generation -->
    <h2>üé® Step 4: Generate New Shoes</h2>
    <p>Create a generation script (<code>generate_shoes.py</code>):</p>

    <div class="code-block">
      from diffusers import StableDiffusionPipeline import torch pipe =
      StableDiffusionPipeline.from_pretrained( "./nike_shoe_generator",
      torch_dtype=torch.float16 ).to("cuda") prompt = "A futuristic Nike running
      shoe with glowing soles, photorealistic 4K" image = pipe(prompt).images[0]
      image.save("generated_nike_shoe.png")
    </div>

    <p>Run it:</p>
    <div class="terminal">python generate_shoes.py</div>

    <!-- Results -->
    <h2>üîç Step 5: Examine the Results</h2>
    <p>Your AI will generate shoes like these:</p>

    <div class="image-grid">
      <img src="generated_shoe_1.jpg" alt="AI-generated Nike shoe" />
      <img src="generated_shoe_2.jpg" alt="Another AI-generated shoe" />
    </div>

    <!-- Ethical Discussion -->
    <div class="ethical-dilemma">
      <h2>‚ö†Ô∏è The Ethical Problem</h2>
      <p>
        <strong>All generated shoes look suspiciously like Nikes</strong>, even
        though we didn't directly copy any design. This raises questions:
      </p>

      <div class="code-block">
        Legal Gray Areas: 1. Does Nike own their "style"? 2. Is this fair use or
        infringement? 3. Who owns AI-generated designs?
      </div>

      <h3>Key Considerations:</h3>
      <ul>
        <li>AI learns like humans do - by observing patterns</li>
        <li>Current laws weren't written for AI-generated content</li>
        <li>Companies are already suing over this exact issue</li>
      </ul>
    </div>

    <!-- Conclusion -->
    <h2>üí≠ Final Thoughts</h2>
    <p>
      This project shows how easily AI can replicate corporate designs. As you
      experiment:
    </p>
    <ul>
      <li>Be transparent about your training data</li>
      <li>Consider the legal implications</li>
      <li>Join the conversation about AI ethics!</li>
    </ul>
  </body>
</html>
