<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Let's Build an AI Shoe Designer</title>
    <link rel="stylesheet" href="style.css" />
  </head>

  <body>
    <h1>Let's Build a Shoe Designer With AI</h1>
    <span class="author-name">Mauricio Mossi</span>
    <span class="divider">•</span>
    <span class="author-name">Tiago Machado Saenz</span>
    <span class="divider">•</span>
    <span class="author-name">Khang Tran</span>
    <span class="divider">•</span>
    <span class="author-name">Haoyuan Xu</span>
    <div class="date">April 23, 2025</div>

    <p>
      In this tutorial, I’ll show you how to build a completely free AI image
      generator that specializes in shoes. Whether you're a designer looking for
      inspiration, a sneakerhead dreaming up the next hype beast release, or
      just curious about AI, this guide will help you turn ideas into visuals
      with no cost beyond your computer’s hardware.
    </p>

    <div>
      <strong> No coding experience? No problem! </strong>
    </div>

    <ul>
      <li>We’ll explain everything in plain language.</li>
      <li>
        You can copy-paste the code without understanding it (like following a
        recipe).
      </li>
      <li>
        Marvel at how just a few lines of code can produce stunning designs.
      </li>
    </ul>

    <!-- How AI Image Generation Works: -->
    <h2>How AI Image Generation Works</h2>

    <p>
      Before we build our shoe designer, let's understand the key components
      that make AI image generation possible. These concepts will help you grasp
      what's happening behind the scenes when your code generates images.
    </p>

    <h3>The Core Components</h3>

    <h4>1. The Model (The Artist's Brain)</h4>
    <ul>
      <li>
        <strong>What it is:</strong> A neural network trained on millions of
        images
      </li>
      <li>
        <strong>Our choice:</strong> Stable Diffusion - an open-source model
        that excels at detailed images
      </li>
      <li>
        <strong>Key capability:</strong> Understands relationships between text
        descriptions and visual features
      </li>
    </ul>

    <div class="analogy">
      Think of this as hiring a world-class artist who has memorized every shoe
      design ever published online, but can combine elements in completely new
      ways.
    </div>

    <h4>2. Diffusers (The Painting Toolkit)</h4>
    <ul>
      <li>
        <strong>What they do:</strong> Implement the "diffusion" process -
        gradually transforming random noise into coherent images
      </li>
      <li>
        <strong>Key advantage:</strong> Handles the complex math so we don't
        have to
      </li>
      <li>
        <strong>Our use:</strong> Provides the Stable Diffusion implementation
        we'll fine-tune
      </li>
    </ul>

    <h4>3. Datasets (The Reference Library)</h4>
    <ul>
      <li>
        <strong>Our collection:</strong> 200-500 Nike shoe images (enough to
        learn style without direct copying)
      </li>
      <li>
        <strong>Preparation:</strong> Images standardized to 512×512 pixels
      </li>
      <li>
        <strong>Critical detail:</strong> The AI learns patterns (swoosh shapes,
        textures) not exact copies
      </li>
    </ul>

    <img src="aigenm.png" style="max-width: 100%; width: auto" />
    <p class="label">Diagram illustrating how AI image generation works.</p>

    <!-- Requirements -->
    <h2>Requirements</h2>
    <p>To follow along with the code, you'll need:</p>
    <ul>
      <li>
        A computer with an <strong>NVIDIA GPU (8GB+ VRAM recommended)</strong>
      </li>
      <li><strong>Python 3.8+</strong> installed</li>
      <li>Basic familiarity with the command line</li>
    </ul>

    <div class="warning">
      <strong>⚠️ Note:</strong> Without a GPU, training will be very slow.
      Consider using
      <a href="https://colab.research.google.com/" target="_blank"
        >Google Colab</a
      >
      for free GPU access.
    </div>

    <!-- Setup -->
    <h2>Step 1: Setup Your Environment</h2>
    <p>
      We'll install the AI "toolkit" — a set of free libraries that enable your
      computer to generate images. Don’t worry about memorizing everything right
      now; you can always revisit this later. To ease any nerves, we’ll walk you
      through exactly what’s being installed.
    </p>
    <div class="terminal">
      pip install torch torchvision --extra-index-url
      https://download.pytorch.org/whl/cu118
    </div>
    <p><strong>What this installs:</strong></p>
    <ul>
      <li>
        <strong>PyTorch (torch)</strong>: The engine that powers our AI. Think
        of it like the operating system for artificial intelligence.
      </li>
      <li>
        <strong>torchvision</strong>: Adds image processing capabilities to
        PyTorch (like teaching the engine to understand pictures).
      </li>
      <li>
        <strong>CUDA 11.8</strong> (via --extra-index-url): Lets your NVIDIA GPU
        accelerate the AI.
      </li>
    </ul>
    <div class="terminal">
      pip install diffusers transformers accelerate datasets
    </div>
    <p><strong>Our AI specialty tools:</strong></p>
    <ul>
      <li>
        <strong>diffusers</strong>: The actual image generator we'll use
        (contains Stable Diffusion - the same tech behind popular AI art tools).
      </li>
      <li>
        <strong>transformers</strong>: Helps the AI understand text prompts (so
        it knows what "futuristic sneaker" means).
      </li>
      <li>
        <strong>accelerate</strong>: Optimizes the AI to run efficiently on your
        hardware.
      </li>
      <li>
        <strong>datasets</strong>: Provides tools to organize our shoe images
        for training.
      </li>
    </ul>
    <div class="note">
      <strong>Why this matters:</strong> Together, these packages form a
      complete AI art studio - like giving Photoshop to a robot artist. The
      total installation will use about 4GB of space.
    </div>
    <p>
      <strong>For non-technical readers:</strong> This is like downloading an
      "AI Art App", but instead of using an app store, we're using Python's
      package system. The commands above handle everything automatically.
    </p>

    <!-- Data Collection -->
    <h2>Step 2: Prepare Shoe Dataset</h2>

    <div class="intro-box">
      <p>
        Every great AI model starts with quality data. For our shoe generator to
        the more the better, try to aim for about
        <strong>200-500 high-quality images</strong>.
      </p>
    </div>

    <img src="images.png" style="max-width: 100%; width: auto" />
    <p class="label">Just a *small* subset... like 4,000 images.</p>

    <h3>How to Gather Images</h3>

    <h4>Manual Collection <span class="recommended">Recommended</span></h4>
    <ul>
      <li>Visit shoe brand websites and authorized retailers</li>
      <li>Save product images one-by-one (high-resolution preferred)</li>
      <li>Organize in a folder named <code>shoe_dataset/</code></li>
    </ul>

    <h4>Alternative Sources</h4>
    <ul>
      <li>
        Public datasets (<a
          href="https://www.kaggle.com/datasets"
          target="_blank"
          >Kaggle</a
        >, Open Images)
      </li>
      <li>Stock photo sites with Creative Commons licenses</li>
      <li>Second-hand marketplaces (eBay product photos)</li>
    </ul>

    <div class="note">
      <p>
        <strong>Data Collection Reality Check:</strong> This is where AI meets
        real-world challenges. To train our shoe designer, we need hundreds of
        images - but manually collecting them would take days. Web Scraping is a
        programmer's solution.
      </p>
    </div>

    <h3>A Word About Web Scraping</h3>
    <p>While automated scraping can save time, consider:</p>
    <ul>
      <li>Most websites prohibit scraping in their Terms of Service</li>
      <li>Brands actively employ anti-bot measures</li>
    </ul>
    <p>
      Learn web scraping concepts ethically using practice sites like
      <a href="http://books.toscrape.com/" target="_blank">books.toscrape.com</a
      >.
    </p>

    <h3>Ready-Made Option</h3>
    <p>For immediate testing, try legally-sourced datasets:</p>
    <p>
      <a href="https://www.kaggle.com/datasets" target="_blank"
        >Search "sneakers" on Kaggle</a
      >
    </p>

    <!-- Training -->
    <h2>Step 3: Train the AI Model</h2>
    <p>
      Now that you've collected hundreds of shoe images, it's time to
      <strong>teach your AI how to design</strong>. This process mimics how
      humans learn - by studying many examples, identifying patterns, and
      practicing recreating them.
    </p>

    <p>
      Create a file, for our example the file is named
      <code>gen.py</code>:
    </p>

    <div class="code-block">
      <pre><code>
    import torch
    from diffusers import StableDiffusionPipeline, UNet2DConditionModel
    from torch.optim import AdamW
    from pathlib import Path

    # 1. Load model with gradient tracking
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16
    ).to("cuda")

    # 2. Enable gradients for UNet
    pipe.unet.train()
    for param in pipe.unet.parameters():
        param.requires_grad = True  # Critical for training

    # 3. Setup optimizer
    optimizer = AdamW(pipe.unet.parameters(), lr=1e-4)

    # 4. Simplified training loop
    for epoch in range(3):  # Start small for testing
        for img_path in Path("./nike_shoes").glob("*.jpg"):
            try:
                # Load and preprocess image
                image = pipe.image_processor.preprocess(Image.open(img_path))
                
                # Convert to latent space
                latents = pipe.vae.encode(image.to(device="cuda", dtype=torch.float16)).latent_dist.sample() * 0.18215
                
                # Forward pass
                noise_pred = pipe.unet(latents, torch.zeros(1).long().to("cuda")).sample
                
                # Dummy loss (replace with real noise prediction in actual training)
                loss = torch.nn.functional.mse_loss(noise_pred, torch.randn_like(noise_pred))
                
                # Backward pass
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()
                
                print(f"Epoch {epoch}, Loss: {loss.item():.4f}")
                
            except Exception as e:
                print(f"Skipping {img_path} due to error: {str(e)}")

    # Save the trained model
    pipe.save_pretrained("./trained_shoe_model")
    </code></pre>
    </div>
    <p>
      <strong>Note on file paths:</strong> In this code, I'm using
      <code>"./shoes"</code> as my folder containing all the training images (in
      JPG format), and saving the final trained model to
      <code>"./trained_shoe_model"</code>. Make sure to:
    </p>
    <ul>
      <li>
        Create a <code>shoes</code> folder in the same directory as your script
      </li>
      <li>Place all your shoe images inside it</li>
      <li>
        The script will automatically create the
        <code>trained_shoe_model</code> folder
      </li>
    </ul>
    <p>Then run the file:</p>
    <div class="terminal">python gen.py</div>

    <img src="takesawhile.png" style="max-width: 100%; width: auto" />
    <p class="label">Okay, so it did take a while.</p>

    <!-- Generation -->
    <h2>Step 4: Generate New Shoes</h2>
    Now that you have a trained model (<code>trained_shoe_model</code>), let's
    create some shoe designs. This file will generate images based on text
    prompts, for our example the file is named <code>generate_shoes.py</code>:

    <div class="code-block">
      <pre><code>
        from diffusers import StableDiffusionPipeline
        import torch

        # Load your trained model
        pipe = StableDiffusionPipeline.from_pretrained(
            "./trained_shoe_model",
            torch_dtype=torch.float16
        ).to("cuda")

        # List of prompts to generate different shoe styles
        prompts = [
            "A futuristic running shoe with neon accents",
            "Classic leather sneaker with minimalist design", 
            "Eco-friendly sports shoe made from recycled materials",
            "High-performance basketball shoe with advanced cushioning"
        ]

        # Generate and save images
        for prompt in prompts:
            image = pipe(prompt, num_inference_steps=30).images[0]
            image.save(f"generated_{prompt[:15].replace(' ', '_')}.png")
            print(f"Generated: {prompt}")
      </code></pre>
    </div>
    <div class="codej-note">
      <p>
        <strong>About the prompts variable:</strong>
      </p>
      <ul>
        <li>
          The <code>prompts</code> list contains text descriptions of the shoe
          designs you want to generate
        </li>
        <li>
          Each string will produce a different image - be as specific or
          creative as you like
        </li>
        <li>
          Example prompt breakdown:
          <code>"A [style] [type of shoe] with [specific features]"</code>
        </li>
      </ul>
    </div>

    <p>Then run the file:</p>
    <div class="terminal">python generate_shoes.py</div>

    <!-- Results -->
    <h2>Step 5: Examine the Results</h2>
    <h3>Prompt: "A futuristic running shoe with neon accents"</h3>
    <img src="s1.png" style="max-width: 100%; width: auto" />

    <h3>Prompt: "Classic leather sneaker with minimalist design"</h3>
    <img src="s2.png" style="max-width: 100%; width: auto" />

    <h3>Prompt: "Eco-friendly sports shoe made from recycled materials"</h3>
    <img src="s3.png" style="max-width: 100%; width: auto" />

    <h3>Prompt: "High-performance basketball shoe with advanced cushioning"</h3>
    <img src="s4.png" style="max-width: 100%; width: auto" />

    <h2>
      Owning Your AI: The Critical Importance of Data Privacy in the Age of
      Artificial Intelligence
    </h2>
    <p>
      In this project, we built a custom AI shoe designer using Stable
      Diffusion, demonstrating how AI can generate creative designs with minimal
      code. However, beyond the technical achievement lies a more pressing
      issue: data privacy and ownership. While large corporations train AI
      models on massive datasets—often without explicit user consent—we showed
      that self-hosting AI models is not only feasible but essential for
      protecting personal data and maintaining control over digital assets.
    </p>

    <h3>The Hidden Cost of AI: Your Data</h3>
    <p>
      To train our shoe designer, we fed 4,000 images into the model—just to
      produce decent results. This raises an alarming question: How much
      personal data do commercial AI services collect to achieve their level of
      sophistication?
    </p>
    <ul>
      <li>
        Cloud AI Services (ChatGPT, Midjourney, etc.) train on petabytes of user
        data, often scraped from the web without explicit permission.
      </li>
      <li>
        Your personal data—social media posts, private messages, browsing
        history—may already be part of these datasets.
      </li>
      <li>
        Third-party hosting means you never truly own the AI models or the data
        they produce.
      </li>
    </ul>
    <h3>The Benefits of Self-Hosting AI</h3>
    <p>
      By running our model locally, we demonstrated key advantages over
      cloud-based AI:
    </p>
    <ul>
      <li>You control what goes into the model (no unethical scraping).</li>
      <li>
        No risk of your private images being stored indefinitely on corporate
        servers.
      </li>
      <li>No hidden data collection or surveillance.</li>
      <li>
        Avoids the "AI data broker" economy where personal information is
        commodified.
      </li>
      <li>
        No recurring subscription fees (unlike services like Midjourney or
        ChatGPT Pro).*
      </li>
      <li>One-time computational cost vs. continuous payments.*</li>
      <li>Fine-tune the model to your exact needs</li>
      <li>Full visibility into training data.</li>
    </ul>

    <p>
    Think about it, our small shoe generator required 4,000 images to
    function, imagine how much data is needed for facial recognition, chatbots,
    preductive algorithnms.
    </p>

  <div class="my-footer">
    <p>— Created by Mauricio Mossi —</p>
  </div>
  </body>
</html>
